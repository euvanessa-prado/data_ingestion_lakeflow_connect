# üìö Data Ingestion com Lakeflow Connect - Guia Did√°tico

## üéØ O que √© este projeto?

Este projeto ensina como **trazer dados de arquivos CSV para dentro do Databricks** de forma organizada e profissional, usando as melhores pr√°ticas de engenharia de dados.

Imagine que voc√™ tem dados de sinistros de seguros em arquivos CSV e precisa:
- Armazenar esses dados de forma segura
- Processar e limpar os dados
- Disponibilizar para an√°lises e relat√≥rios

Este projeto mostra **4 formas diferentes** de fazer isso!

---

## üèóÔ∏è Conceitos Fundamentais

### 1. Unity Catalog - O "Organizador" dos seus dados

Pense no Unity Catalog como um **sistema de pastas super organizado**:

```
Unity Catalog
‚îî‚îÄ‚îÄ Cat√°logo (smart_claims_dev)          ‚Üê Como uma "pasta principal"
    ‚îú‚îÄ‚îÄ Schema 00_landing                 ‚Üê Subpasta para dados brutos
    ‚îú‚îÄ‚îÄ Schema 01_bronze                  ‚Üê Subpasta para dados originais
    ‚îú‚îÄ‚îÄ Schema 02_silver                  ‚Üê Subpasta para dados limpos
    ‚îî‚îÄ‚îÄ Schema 03_gold                    ‚Üê Subpasta para dados prontos
```

**Por que usar?**
- Organiza√ß√£o clara dos dados
- Controle de quem pode acessar o qu√™
- Facilita encontrar as informa√ß√µes

### 2. Arquitetura Medallion - As "3 Camadas de Qualidade"

√â como processar caf√©:
- **ü•â Bronze (Landing)**: Gr√£os crus (dados como chegaram)
- **ü•à Silver**: Gr√£os torrados (dados limpos e validados)
- **ü•á Gold**: Caf√© pronto (dados agregados para consumo)

**Benef√≠cios:**
- Sempre tem os dados originais guardados (Bronze)
- Pode refazer o processamento se algo der errado
- Dados ficam cada vez mais refinados

### 3. Volumes - O "HD Externo" do Databricks

Volumes s√£o espa√ßos para guardar **arquivos** (CSV, JSON, imagens, etc):

```sql
CREATE VOLUME smart_claims_dev.00_landing.sql_server
```

**Tradu√ß√£o:** "Crie um espa√ßo de armazenamento chamado 'sql_server' dentro da pasta '00_landing'"

**Onde usar:** `/Volumes/smart_claims_dev/00_landing/sql_server/claims.csv`

---

## üìñ Explica√ß√£o dos Notebooks

### Notebook 1: Cria√ß√£o de Cat√°logos e Schemas

**O que faz:** Cria a estrutura organizacional b√°sica

#### Comando 1: Criar o Cat√°logo
```sql
CREATE CATALOG IF NOT EXISTS smart_claims_dev
COMMENT 'Cat√°logo principal para o projeto Smart Claims'
```

**Explica√ß√£o linha por linha:**
- `CREATE CATALOG` = "Crie uma pasta principal"
- `IF NOT EXISTS` = "S√≥ crie se ainda n√£o existir" (evita erros)
- `smart_claims_dev` = Nome do cat√°logo
- `COMMENT` = Descri√ß√£o para documentar

#### Comando 2: Criar os Schemas (Camadas)
```sql
CREATE SCHEMA IF NOT EXISTS smart_claims_dev.00_landing
COMMENT 'Zona de landing - recep√ß√£o de dados brutos'
```

**Explica√ß√£o:**
- `CREATE SCHEMA` = "Crie uma subpasta"
- `smart_claims_dev.00_landing` = "Dentro do cat√°logo smart_claims_dev, crie a pasta 00_landing"
- Repete para: `01_bronze`, `02_silver`, `03_gold`

#### Comando 3: Verificar o que foi criado
```sql
SHOW SCHEMAS IN smart_claims_dev
```

**Resultado esperado:**
```
00_landing
01_bronze
02_silver
03_gold
```

---

### Notebook 2: Cria√ß√£o de Volumes

**O que faz:** Cria espa√ßos para armazenar arquivos

#### Comando: Criar Volume
```sql
CREATE VOLUME IF NOT EXISTS smart_claims_dev.00_landing.sql_server
COMMENT 'Volume para armazenar dados do SQL Server'
```

**Explica√ß√£o:**
- Cria um "HD externo" chamado `sql_server`
- Localiza√ß√£o: dentro do schema `00_landing`
- Aqui voc√™ vai colocar os arquivos CSV

**Como usar depois:**
```sql
-- Listar arquivos no volume
LIST '/Volumes/smart_claims_dev/00_landing/sql_server'

-- Ler um arquivo
SELECT * FROM csv.`/Volumes/smart_claims_dev/00_landing/sql_server/claims.csv`
```

---

### Notebook 3: Data Ingestion (Ingest√£o de Dados)

**O que faz:** Mostra 3 formas de trazer dados do CSV para tabelas

#### M√©todo 1: Explorar os dados primeiro
```sql
SELECT *
FROM csv.`/Volumes/smart_claims_dev/00_landing/sql_server/claims.csv`
```

**Explica√ß√£o:**
- `csv.` = "Leia como arquivo CSV"
- Backticks `` ` `` = Indicam um caminho de arquivo
- √ötil para **ver os dados antes** de criar a tabela

#### M√©todo 2: CREATE TABLE AS SELECT (CTAS)
```sql
CREATE TABLE smart_claims_dev.01_bronze.claims
AS SELECT *
FROM read_files(
  '/Volumes/smart_claims_dev/00_landing/sql_server/claims.csv',
  format => 'csv'
)
```

**Explica√ß√£o passo a passo:**
1. `CREATE TABLE` = "Crie uma tabela"
2. `AS SELECT` = "Usando os dados que vou buscar"
3. `read_files()` = Fun√ß√£o que l√™ arquivos
4. `format => 'csv'` = "O arquivo √© CSV"

**Quando usar:** Carga inicial de dados (primeira vez)

#### M√©todo 3: Python com PySpark
```python
# 1. Ler o arquivo CSV
df = (
    spark.read
    .format("csv")
    .option("header", True)  # Primeira linha √© cabe√ßalho
    .load("/Volumes/smart_claims_dev/00_landing/sql_server/claims.csv")
)

# 2. Salvar como tabela
df.write.mode("overwrite").saveAsTable("smart_claims_dev.01_bronze.claims")

# 3. Ler a tabela criada
claims_table = spark.table("smart_claims_dev.01_bronze.claims")
display(claims_table)
```

**Explica√ß√£o:**
- `spark.read` = Objeto para ler dados
- `.option("header", True)` = "A primeira linha tem os nomes das colunas"
- `.mode("overwrite")` = "Se a tabela existir, substitua"
- `display()` = Mostra os dados na tela

**Quando usar:** Quando precisa de mais controle ou transforma√ß√µes em Python

#### M√©todo 4: COPY INTO (Incremental)
```sql
-- Primeiro: Criar a estrutura da tabela
CREATE TABLE smart_claims_dev.01_bronze.claims (
  claim_no STRING,
  policy_no STRING,
  claim_date STRING,
  -- ... outras colunas
)

-- Depois: Copiar os dados
COPY INTO smart_claims_dev.01_bronze.claims
FROM '/Volumes/smart_claims_dev/00_landing/sql_server/claims.csv'
FILEFORMAT = CSV
FORMAT_OPTIONS ('header'='true')
```

**Explica√ß√£o:**
- `COPY INTO` = "Copie dados para dentro da tabela"
- **Vantagem:** S√≥ copia arquivos novos (n√£o duplica)
- **Quando usar:** Cargas di√°rias/incrementais

---

### Notebook 4: Auto Loader + Lakeflow (Streaming)

**O que faz:** Ingest√£o autom√°tica e cont√≠nua de dados

#### Conceito: Streaming vs Batch

**Batch (Notebooks anteriores):**
- Voc√™ executa manualmente
- Processa tudo de uma vez
- Como baixar um filme completo

**Streaming (Auto Loader):**
- Executa automaticamente
- Processa novos arquivos conforme chegam
- Como assistir Netflix (streaming cont√≠nuo)

#### Comando: Criar Streaming Table
```sql
CREATE OR REFRESH STREAMING LIVE TABLE smart_claims_dev.01_bronze.claims
AS
SELECT
  *,
  _metadata.file_path AS input_file,
  _metadata.file_modification_time AS input_file_mtime,
  current_timestamp() AS ingested_at
FROM cloud_files(
  "/Volumes/smart_claims_dev/00_landing/sql_server",
  "csv",
  map(
    "header", "true",
    "cloudFiles.inferColumnTypes", "true",
    "cloudFiles.schemaEvolutionMode", "addNewColumns",
    "pathGlobFilter", "claims.csv"
  )
)
```

**Explica√ß√£o detalhada:**

1. **CREATE OR REFRESH STREAMING LIVE TABLE**
   - `STREAMING` = Processa dados continuamente
   - `LIVE` = Sempre atualizada
   - `OR REFRESH` = Atualiza se j√° existir

2. **Colunas extras de metadados:**
   ```sql
   _metadata.file_path AS input_file
   ```
   - Guarda de qual arquivo veio cada linha
   - √ötil para rastreabilidade

   ```sql
   current_timestamp() AS ingested_at
   ```
   - Registra quando o dado foi ingerido
   - √ötil para auditoria

3. **cloud_files() - O Auto Loader:**
   - `"/Volumes/.../sql_server"` = Pasta para monitorar
   - `"csv"` = Tipo de arquivo
   
4. **Configura√ß√µes (map):**
   ```sql
   "header", "true"
   ```
   - Primeira linha √© cabe√ßalho
   
   ```sql
   "cloudFiles.inferColumnTypes", "true"
   ```
   - Detecta automaticamente se √© n√∫mero, texto, data, etc.
   
   ```sql
   "cloudFiles.schemaEvolutionMode", "addNewColumns"
   ```
   - Se aparecer coluna nova no CSV, adiciona automaticamente
   
   ```sql
   "pathGlobFilter", "claims.csv"
   ```
   - S√≥ processa arquivos com nome "claims.csv"

#### Agendamento
```sql
CREATE OR REFRESH STREAMING TABLE smart_claims_dev.01_bronze.claims
SCHEDULE EVERY 1 WEEK
```

**Explica√ß√£o:**
- `SCHEDULE EVERY 1 WEEK` = Executa automaticamente toda semana
- Pode usar: `1 HOUR`, `1 DAY`, `1 WEEK`

---

## üîÑ Fluxo Completo do Projeto

```
1. PREPARA√á√ÉO
   ‚îú‚îÄ‚îÄ Criar Cat√°logo (smart_claims_dev)
   ‚îú‚îÄ‚îÄ Criar Schemas (00_landing, 01_bronze, 02_silver, 03_gold)
   ‚îî‚îÄ‚îÄ Criar Volume (sql_server)

2. UPLOAD DE DADOS
   ‚îî‚îÄ‚îÄ Colocar claims.csv no volume

3. INGEST√ÉO (Escolha uma op√ß√£o)
   ‚îú‚îÄ‚îÄ Op√ß√£o A: CTAS (carga √∫nica)
   ‚îú‚îÄ‚îÄ Op√ß√£o B: Python (mais controle)
   ‚îú‚îÄ‚îÄ Op√ß√£o C: COPY INTO (incremental manual)
   ‚îî‚îÄ‚îÄ Op√ß√£o D: Auto Loader (streaming autom√°tico) ‚≠ê Recomendado

4. RESULTADO
   ‚îî‚îÄ‚îÄ Tabela smart_claims_dev.01_bronze.claims pronta para uso
```

---

## üìä Dados do Projeto

O arquivo `claims.csv` cont√©m informa√ß√µes de sinistros de seguros:

| Coluna | Descri√ß√£o | Exemplo |
|--------|-----------|---------|
| claim_no | N√∫mero do sinistro | CLM001 |
| policy_no | N√∫mero da ap√≥lice | POL12345 |
| claim_date | Data do sinistro | 2024-01-15 |
| injury | Valor de danos pessoais | 5000.00 |
| property | Valor de danos materiais | 15000.00 |
| vehicle | Valor de danos ao ve√≠culo | 8000.00 |
| total | Valor total | 28000.00 |
| collision_type | Tipo de colis√£o | Rear-end |
| suspicious_activity | Atividade suspeita? | Yes/No |

---

## üéì Compara√ß√£o dos M√©todos

| M√©todo | Quando Usar | Vantagens | Desvantagens |
|--------|-------------|-----------|--------------|
| **CTAS** | Carga inicial √∫nica | Simples e r√°pido | N√£o detecta novos arquivos |
| **Python** | Transforma√ß√µes complexas | Muito flex√≠vel | Mais c√≥digo |
| **COPY INTO** | Cargas di√°rias manuais | Evita duplicatas | Precisa executar manualmente |
| **Auto Loader** | Produ√ß√£o (autom√°tico) | Totalmente autom√°tico, schema evolution | Mais complexo de configurar |

---

## üöÄ Como Executar

### Passo 1: Preparar o ambiente
```sql
-- Execute o Notebook 1
-- Cria: Cat√°logo + Schemas
```

### Passo 2: Criar volumes
```sql
-- Execute o Notebook 2
-- Cria: Volume para arquivos
```

### Passo 3: Upload do arquivo
```python
# Via interface do Databricks ou comando:
dbutils.fs.cp("file:/local/claims.csv", 
              "/Volumes/smart_claims_dev/00_landing/sql_server/claims.csv")
```

### Passo 4: Escolher m√©todo de ingest√£o
```sql
-- Para come√ßar: Use Notebook 3 (CTAS)
-- Para produ√ß√£o: Use Notebook 4 (Auto Loader)
```

---

## üí° Dicas e Boas Pr√°ticas

### 1. Sempre use IF NOT EXISTS
```sql
CREATE CATALOG IF NOT EXISTS smart_claims_dev
```
‚úÖ Evita erros se j√° existir

### 2. Documente com COMMENT
```sql
CREATE SCHEMA smart_claims_dev.01_bronze
COMMENT 'Camada Bronze - dados brutos'
```
‚úÖ Facilita entender depois

### 3. Adicione metadados de auditoria
```sql
SELECT 
  *,
  current_timestamp() AS ingested_at,
  _metadata.file_path AS source_file
```
‚úÖ Rastreabilidade completa

### 4. Use nomenclatura padronizada
```
00_landing  ‚Üê N√∫meros ajudam na ordena√ß√£o
01_bronze
02_silver
03_gold
```

### 5. Prefira Auto Loader para produ√ß√£o
- Detecta novos arquivos automaticamente
- Schema evolution
- Checkpoint para n√£o reprocessar

---

## üîç Comandos √öteis para Explora√ß√£o

```sql
-- Ver cat√°logos dispon√≠veis
SHOW CATALOGS;

-- Ver schemas de um cat√°logo
SHOW SCHEMAS IN smart_claims_dev;

-- Ver tabelas de um schema
SHOW TABLES IN smart_claims_dev.01_bronze;

-- Ver volumes
SHOW VOLUMES IN smart_claims_dev.00_landing;

-- Listar arquivos em um volume
LIST '/Volumes/smart_claims_dev/00_landing/sql_server';

-- Ver estrutura de uma tabela
DESCRIBE TABLE smart_claims_dev.01_bronze.claims;

-- Ver detalhes completos
DESCRIBE TABLE EXTENDED smart_claims_dev.01_bronze.claims;

-- Ver dados
SELECT * FROM smart_claims_dev.01_bronze.claims LIMIT 10;

-- Contar registros
SELECT COUNT(*) FROM smart_claims_dev.01_bronze.claims;
```

---

## üéØ Pr√≥ximos Passos

Depois de dominar a ingest√£o (Bronze), voc√™ pode:

1. **Criar camada Silver:**
   - Limpar dados (remover nulos, duplicatas)
   - Converter tipos (string ‚Üí date, decimal)
   - Validar regras de neg√≥cio

2. **Criar camada Gold:**
   - Agrega√ß√µes (total por m√™s, por tipo)
   - Joins com outras tabelas
   - M√©tricas de neg√≥cio

3. **Adicionar governan√ßa:**
   - Controle de acesso (quem pode ver o qu√™)
   - Data quality checks
   - Lineage (rastreamento de origem)

---

## üìö Gloss√°rio

- **Catalog**: N√≠vel mais alto de organiza√ß√£o no Unity Catalog
- **Schema**: Agrupamento l√≥gico de tabelas (equivalente a "database")
- **Volume**: Espa√ßo para armazenar arquivos n√£o estruturados
- **Delta Lake**: Formato de armazenamento transacional (ACID)
- **Auto Loader**: Ferramenta para ingest√£o incremental autom√°tica
- **Streaming Table**: Tabela que processa dados continuamente
- **CTAS**: CREATE TABLE AS SELECT - cria tabela a partir de query
- **Schema Evolution**: Adapta√ß√£o autom√°tica quando estrutura muda

---

## üë§ Autor

**Vanessa Prado**
- GitHub: [@euvanessa-prado](https://github.com/euvanessa-prado)

---

## üìÑ Licen√ßa

Projeto educacional - livre para uso e aprendizado! üéì
